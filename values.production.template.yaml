osm-seed:

  # ====================================================================================================
  # ====================================================================================================
  # ==================================Global Configurations=============================================
  # ====================================================================================================
  # ====================================================================================================
  environment: production
  # cloudProvider is provider where you are going to deploy osm-seed, it could be: aws, gcp, minikube
  cloudProvider: aws

  # ====================================================================================================
  # AWS: In case you are using the cloudProvider=aws set the below variables, We are assuming the nodes has a policies access to S3
  # ====================================================================================================
  AWS_S3_BUCKET: {{PRODUCTION_S3_BUCKET}}

  # AWS SSL ARN
  AWS_SSL_ARN: {{AWS_SSL_ARN}}

  # Specify serviceType.
  #
  # serviceType can be one of three values: 'NodePort', 'ClusterIP' or 'LoadBalancer'
  # Use `NodePort` for local testing on minikube.
  #
  # The recommended setting is `ClusterIP`, and then following the instructions to
  # point a DNS record to the cluster IP address. This will setup the ingress rules
  # for all services as subdomains and configure SSL using Lets Encrypt.
  #
  # If you specify `LoadBalancer` as the service type, if you also specify
  # an `AWS_SSL_ARN` that is a wildcart certificate, that will be configured
  # as the SSL certificate for your services. Else, you will need to configure
  # SSL separately. 
  serviceType: LoadBalancer

  # Domain that is pointed to the clusterIP
  # You will need to create an A record like *.osmseed.example.com pointed to the ClusterIP
  # Then, the cluster configuration will setup services at their respective subdomains:
  # - web.osmseed.example.com
  # - overpass.osmseed.example.com
  # - nominatim.osmseed.example.com
  # - etc.
  domain: openhistoricalmap.org

  # ====================================================================================================
  # Configuration for Lets Encrypt setup
  # ====================================================================================================

  # Admin Email address used when generating Lets Encrypt certificates.
  # You will be notified of expirations, etc. on this email address.
  adminEmail: ruben@developmentseed.org

  # ====================================================================================================
  # Variables for osm-seed database
  # ====================================================================================================
  db:
    enabled: true
    # For node selector you should create the node with a label "nodegroup_type"
    nodeSelector:
      enabled: true
      label_key: nodegroup_type
      label_value: db
    env:
      POSTGRES_DB: {{PRODUCTION_DB}}
      POSTGRES_USER: {{PRODUCTION_DB_USER}}
      POSTGRES_PASSWORD: {{PRODUCTION_DB_PASSWORD}}
    persistenceDisk:
      enabled: true
      accessMode: ReadWriteOnce
      mountPath: /var/lib/postgresql/data
      subPath: postgresql-db
      # In case cloudProvider: aws
      AWS_ElasticBlockStore_volumeID : {{PRODUCTION_DB_EBS}}
      AWS_ElasticBlockStore_size: 500Gi
    resources:
      enabled: false
      requests:
        memory: "10Gi"
        cpu: "5"
      limits:
        memory: "10Gi"
        cpu: "5"

  # ====================================================================================================
  # Variables for osm-seed website
  # ====================================================================================================
  web:
    enabled: true
    replicaCount: 2
    # Set staticIp, if you are using cloudProvider=gcp
    staticIp: c
    serviceAnnotations:
      service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: "300"
    nodeSelector:
      enabled: true
      label_key: nodegroup_type
      label_value: web
    env:
      MAILER_ADDRESS: {{MAILER_ADDRESS}}
      MAILER_DOMAIN: {{MAILER_DOMAIN}}
      MAILER_USERNAME: {{MAILER_USERNAME}}
      MAILER_PASSWORD: {{MAILER_PASSWORD}}
      OSM_id_key: {{PRODUCTION_ID_APPLICATION}}
      OAUTH_CLIENT_ID: {{PRODUCTION_OAUTH_CLIENT_ID}}
      OAUTH_KEY: {{PRODUCTION_OAUTH_KEY}}
      MAILER_FROM: no-reply@openhistoricalmap.org
      NOMINATIM_URL: nominatim-api.openhistoricalmap.org
      OVERPASS_URL: overpass-api.openhistoricalmap.org
      NEW_RELIC_LICENSE_KEY: {{PRODUCTION_NEW_RELIC_LICENSE_KEY}}
      NEW_RELIC_APP_NAME: {{PRODUCTION_NEW_RELIC_APP_NAME}}
    resources:
      enabled: true
      requests:
        memory: "8GB"
        cpu: "2"
      limits:
        memory: "8GB"
        cpu: "2"
    autoscaling:
      enabled: true
      minReplicas: 2
      maxReplicas: 10
      cpuUtilization: 80
  # ====================================================================================================
  # Variables for memcached. Memcached is used to store session cookies
  # ====================================================================================================
  memcached:
    enabled: true
    nodeSelector:
      enabled: false
      label_key: nodegroup_type
      label_value: web
    resources:
      enabled: false
      requests:
        memory: "8Gi"
        cpu: "2"
      limits:
        memory: "8Gi"
        cpu: "2"

  # ====================================================================================================
  # Variables for osm-seed for osmosis, this configuration os to get the planet dump files from apidb
  # ====================================================================================================
  planetDump:
    enabled: true
    schedule: '0 0 * * *'
    nodeSelector:
      enabled: true
      label_key: nodegroup_type
      label_value: job
    env:
      OVERWRITE_PLANET_FILE: false
    resources:
      enabled: false
      requests:
        memory: "4Gi"
        cpu: "2"
      limits:
        memory: "8Gi"
        cpu: "4"

  # ====================================================================================================
  # Variables for full-history container
  # ====================================================================================================
  fullHistory:
    enabled: true
    schedule: '0 0 * * 0'
    nodeSelector:
      enabled: true
      label_key: nodegroup_type
      label_value: job
    env:
      OVERWRITE_FHISTORY_FILE: false
    resources:
      enabled: false
      requests:
        memory: "4Gi"
        cpu: "2"
      limits:
        memory: "8Gi"
        cpu: "4"

  # ====================================================================================================
  # Variables for id-editor
  # ====================================================================================================
  idEditor:
    enabled: false
    replicaCount: 1
    # Set staticIp, if you are using cloudProvider=gcp
    staticIp: 35.233.232.82
    nodeSelector:
      enabled: true
      label_key: nodegroup_type
      label_value: web
    env:
      ID_EDITOR_PORT: 80
      OSM_API_PROTOCOL: http
      OSM_API_DOMAIN: aaee232301c4644ff971899b35406d18-998593153.us-east-1.elb.amazonaws.com
      OAUTH_CONSUMER_KEY: LQCgtGKQ0MqTLnxxkQ0MZZz8NQmHjAcA21o7Thua
      OAUTH_SECRET: YF2df1It12j1yFYPAdZgtafzVW77L3R35qY34QDp
    resources:
      enabled: false
      requests:
        memory: "300Mi"
        cpu: "0.4"
      limits:
        memory: "400Mi"
        cpu: "0.5"
  # ====================================================================================================
  # Variables for replication-job, Configuration to create the replication files by, minute, hour, or day
  # ====================================================================================================
  replicationJob:
    enabled: true
    nodeSelector:
      enabled: true
      label_key: nodegroup_type
      label_value: web
    resources:
      enabled: false
      requests:
        memory: "20Gi"
        cpu: "8"
      limits:
        memory: "24Gi"
        cpu: "10"

  # ====================================================================================================
  # Variables for osm-seed to pupulate the apidb
  # ====================================================================================================
  populateApidb:
    enabled: false
    env:
      URL_FILE_TO_IMPORT: 'https://storage.googleapis.com/osm-seed/osm-processor/history-latest-to-import-output.pbf'
    resources:
      enabled: false
      requests:
        memory: "1Gi"
        cpu: "2"
      limits:
        memory: "2Gi"
        cpu: "2.5"

  # ====================================================================================================
  # Variables to start a pod to process osm files
  # ====================================================================================================
  osmProcessor:
    enabled: false
    env: 
      URL_FILE_TO_PROCESS: 'https://storage.googleapis.com/osm-seed/planet/full-history/history-latest-to-import.pbf'
      OSM_FILE_ACTION: simple_pbf
    resources:
      enabled: false
      requests:
        memory: "14Gi"
        cpu: "4"
      limits:
        memory: "16Gi"
        cpu: "4"

  # ====================================================================================================
  # Variables for restoring the DB
  # ====================================================================================================

  dbBackupRestore:
    enabled: true
    schedule: '0 0 * * *'
    nodeSelector:
      enabled: true
      label_key: nodegroup_type
      label_value: job
    env:
      DB_ACTION: backup
      RESTORE_URL_FILE: https://osmseed-production-db.s3.us-east-1.amazonaws.com/database/osmseed-db-220803_1606.sql.gz?response-content-disposition=inline&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEDcaCXNhLWVhc3QtMSJIMEYCIQC6oYShK01LFCHNNOP0%2Bch5uKeAcpSmfRLxnaaygUYd5QIhAKt0OtxclFyJrX1qqdOfOgcylfVGBi%2FizMIIISenxD%2FbKoQDCJD%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQAhoMNjE4MzgwMjQyMjQ3IgzdtXrtIBspySZIJ0Yq2AJ0RovZahua04PQ%2FBWVGLhmQPxRiN6Pe5evt2FUuVFdrSMGaqfxo3YAGTezOmviYoqtrHf7NZHRcHQx9RTB4Nk2rmeZfQ9xepB7semK0G3VbzDqsVTzglFDxk52xqpESYYf6vVbORyBDJvjvlCjUAXLH1PqOlj%2FFDd5A3UK3%2FCSJc9JfYh1LVkz4md6ug3mh0KYpUL0%2FipBVpQTcN0PCkVJTTPWOBXmn9qnYMUJg2LNRVMkgIr7AA2MmmSVzPhj%2FfnaHIXCCbHlJ5RA9IgpftC%2FEvTrP2cvgcV03YOWSq9sSMg%2B%2B0xDWn7stI9PsKoakHX%2B%2BtsxHimJ4uGTY8I7DsV915Kzgx1aRlJ5MYjOtbSuMOfhZP6FSwLGRTPw7qvS0kLFKHAwCYLsd7GF6%2FHadTbLSJ0Zx0EqPYVjyIKfwZ5fu204xUkGhCqBlHuQBQhoG%2FMxcnYf53NoSTChm6qXBjqyAkr7doHwSC9HTJYlIq7gixhkZ29BfaHp8jq0gIBW7aAEC3idFdN2ZQd9pHQAgN4fKYrOmC%2Bbf9njZH91%2BEvzwpEHXyho8E8lPSQJGJZnAquRzJkzJ23%2F4zF51Rf2WMSpmYMHyWXodLLP4yYj%2Bgk%2Bg%2FbUsDYhkq4%2B%2F5%2Bf7YLCmvi%2BdO%2B5GEZEa%2B1iPghxd%2BH8eQk9jUlebsI3fh01f%2Bv6TbzgGieM7eqXYeH0JTZDZGEJlPdbUzMHKcj6G6kuTX4nvD9YDPQzUYAoVwu2gwjvrjaHRaK8NKMlEC7JCIlsWrVzjVR%2FtXlBybrZ5rSdZNeTIDDof5lS8O%2F9qqyhTel4pObDPNosj6jCOVPe3geM5ZNZVbL4ATUdJ5oU3BcTm%2FMcerATv%2FysoVrskKNuDMjHoT3fkA%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20220803T172639Z&X-Amz-SignedHeaders=host&X-Amz-Expires=2400&X-Amz-Credential=ASIAY76SVVVDSEAYVNUG%2F20220803%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=6ed260d9d775bbc6b0d4f5e08575552270c970a81afa2254f87b62c3b97730c2
      CLEAN_BACKUPS: false
      AWS_S3_BUCKET: {{PRODUCTION_DB_BACKUP_S3_BUCKET}}
    resources:
      enabled: false
      requests:
        memory: "10Gi"
        cpu: "3"
      limits:
        memory: "10Gi"
        cpu: "3"

  # ====================================================================================================
  # Variables for tiler-db
  # ====================================================================================================

  tilerDb:
    enabled: true
    nodeSelector:
      enabled: true
      label_key: nodegroup_type
      label_value: web
    env:
      POSTGRES_HOST: {{PRODUCTION_TILER_DB_HOST}}
      POSTGRES_DB: {{PRODUCTION_TILER_DB}}
      POSTGRES_USER: {{PRODUCTION_TILER_DB_USER}}
      POSTGRES_PASSWORD: {{PRODUCTION_TILER_DB_PASSWORD}}
      POSTGRES_PORT: 5432
      # for 20GB
      POSTGRES_DB_MAX_CONNECTIONS: 500
      POSTGRES_DB_SHARED_BUFFERS: 5GB
      POSTGRES_DB_WORK_MEM: 15MB
      POSTGRES_DB_MAINTENANCE_WORK_MEM: 1GB
      POSTGRES_DB_EFFECTIVE_CACHE_SIZE: 10GB
    persistenceDisk:
      enabled: true
      accessMode: ReadWriteOnce
      mountPath: /var/lib/postgresql/data
      subPath: postgresql-d
      # In case cloudProvider: aws
      AWS_ElasticBlockStore_volumeID : {{PRODUCTION_TILER_DB_EBS}}
      AWS_ElasticBlockStore_size: 1000Gi
    resources:
      enabled: true
      requests:
        memory: "20Gi"
        cpu: "4"
      limits:
        memory: "20Gi"
        cpu: "4"
  # ====================================================================================================
  # Variables for tiler-imposm
  # ====================================================================================================

  tilerImposm:
    enabled: true
    nodeSelector:
      enabled: true
      label_key: nodegroup_type
      label_value: web
    env:
      TILER_IMPORT_FROM: osm
      TILER_IMPORT_PBF_URL: http://s3.amazonaws.com/planet.openhistoricalmap.org/planet/planet-230727_1030.osm.pbf
      REPLICATION_URL: http://s3.amazonaws.com/planet.openhistoricalmap.org/replication/minute/
      OVERWRITE_STATE: true
      SEQUENCE_NUMBER: 929000
    persistenceDisk:
      enabled: true
      accessMode: ReadWriteOnce
      mountPath: /mnt/data
      # In case cloudProvider: aws
      AWS_ElasticBlockStore_volumeID: {{PRODUCTION_TILER_IMPOSM_EBS}}
      AWS_ElasticBlockStore_size: 100Gi
    resources:
      enabled: true
      requests:
        memory: "16Gi"
        cpu: "2"
      limits:
        memory: "24Gi"
        cpu: "3"
  # ====================================================================================================
  # Variables for tiler-server
  # ====================================================================================================

  tilerServer:
    enabled: true
    nodeSelector:
      enabled: true
      label_key: nodegroup_type
      label_value: web
    replicaCount: 2
    commad: './start.sh'
    serviceAnnotations:
      service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: "300"
    env:
      TILER_SERVER_PORT: 9090
      TILER_CACHE_TYPE: s3
      TILER_CACHE_BASEPATH: /mnt/data
      TILER_CACHE_MAX_ZOOM: 22
      # in case s3
      TILER_CACHE_REGION: us-east-1
      TILER_CACHE_BUCKET: tiler-cache-production
      TILER_CACHE_AWS_ACCESS_KEY_ID: {{PRODUCTION_TILER_CACHE_AWS_ACCESS_KEY_ID}}
      TILER_CACHE_AWS_SECRET_ACCESS_KEY: {{PRODUCTION_TILER_CACHE_AWS_SECRET_ACCESS_KEY}}
    # In case you use TILER_CACHE_TYPE: file with  persistenceDisk 
    persistenceDisk:
      enabled: false
      accessMode: ReadWriteOnce
      mountPath: /mnt/data
      # In case cloudProvider: aws
      AWS_ElasticBlockStore_volumeID : {{PRODUCTION_TILER_SERVER_EBS}}
      AWS_ElasticBlockStore_size: 100Gi
    resources:
      enabled: true
      requests:
        memory: "2Gi"
        cpu: "1"
      limits:
        memory: "10Gi"
        cpu: "2"
    autoscaling:
      enabled: true
      minReplicas: 1
      maxReplicas: 2
      cpuUtilization: 60  
  # ====================================================================================================
  # Variables for tiler-server cache cleaner, only avaliable in case the TILER_CACHE_TYPE = s3  
  # ====================================================================================================
  tilerServerCacheCleaner:
    enabled: true
    nodeSelector:
      enabled: true
      label_key: nodegroup_type
      label_value: web
    replicaCount: 1
    command: './cache_cleaner.sh'
    resources:
      enabled: true
      requests:
        memory: "8Gi"
        cpu: "1"
      limits:
        memory: "10Gi"
        cpu: "2"
    autoscaling:
      enabled: false
      minReplicas: 1
      maxReplicas: 2
      cpuUtilization: 60
  # ====================================================================================================
  # Variables for tiler-visor
  # ====================================================================================================
  tilerVisor:
    enabled: false
    replicaCount: 1
    nodeSelector:
      enabled: true
      label_key: nodegroup_type
      label_value: web
    # Set staticIp, if you are using cloudProvider=gcp
    staticIp: 35.233.232.82
    env:
      TILER_VISOR_PROTOCOL: http
      TILER_VISOR_PORT: 8081
    resources:
      enabled: false
      requests:
        memory: "1Gi"
        cpu: "2"
      limits:
        memory: "2Gi"
        cpu: "2"

  # ====================================================================================================
  # Variables for Tasking Manager API
  # ====================================================================================================

  tmApi:
    enabled: true
    nodeSelector:
      enabled: true
      label_key: nodegroup_type
      label_value: web
    replicaCount: 2
    staticIp: c
    serviceAnnotations:
      service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: "300"
    env:
      POSTGRES_HOST: {{PRODUCTION_TM_API_DB_HOST}}
      POSTGRES_DB: {{PRODUCTION_TM_API_DB}}
      POSTGRES_PASSWORD: {{PRODUCTION_TM_API_DB_PASSWORD}}
      POSTGRES_USER: {{PRODUCTION_TM_API_DB_USER}}
      POSTGRES_PORT: 5432
      TM_ORG_NAME: 'OpenHistoricalMap'
      TM_ORG_CODE: 'OHM'
      TM_ORG_URL: 'openhistoricalmap.org'
      TM_ORG_PRIVACY_POLICY_URL: 'openhistoricalmap.org/copyright'
      TM_ORG_GITHUB: 'github.com/openhistoricalmap'
      OSM_SERVER_URL: 'https://openhistoricalmap.org'
      OSM_NOMINATIM_SERVER_URL: 'https://nominatim-api.openhistoricalmap.org'
      OSM_REGISTER_URL: 'https://openhistoricalmap.org/user/new'
      ID_EDITOR_URL: 'https://openhistoricalmap.org/edit?editor=id'
      POTLATCH2_EDITOR_URL: 'https://openhistoricalmap.org/edit?editor=potlatch2'
      TM_SECRET: {{PRODUCTION_TM_API_SECRET}}
      TM_CONSUMER_KEY: {{PRODUCTION_TM_API_CONSUMER_KEY}}
      TM_CONSUMER_SECRET: {{PRODUCTION_TM_API_CONSUMER_SECRET}}
      TM_EMAIL_FROM_ADDRESS: 'no-reply@openhistoricalmap.org'
      TM_SMTP_HOST: 'email-smtp.us-east-1.amazonaws.com'
      TM_SMTP_PORT: 25
      TM_SMTP_USER: {{MAILER_USERNAME}}
      TM_SMTP_PASSWORD: {{MAILER_PASSWORD}}
      TM_DEFAULT_LOCALE: 'en'
      TM_APP_API_URL: 'https://tm-api.openhistoricalmap.org'
      TM_APP_BASE_URL: 'https://tasks.openhistoricalmap.org'
      TM_IMPORT_MAX_FILESIZE: 3000000
      TM_MAX_AOI_AREA: 15000
    resources:
      enabled: false
      requests:
        memory: "1Gi"
        cpu: "2"
      limits:
        memory: "2Gi"
        cpu: "2"


  
  # ====================================================================================================
  # Variables for nominatim api
  # ====================================================================================================
  nominatimApi:
    enabled: true
    serviceAnnotations:
      service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: "300"
    replicaCount: 1
    env:
      PBF_URL: http://s3.amazonaws.com/planet.openhistoricalmap.org/planet/planet-230727_1030.osm.pbf
      REPLICATION_URL: http://planet.openhistoricalmap.org.s3.amazonaws.com/replication/minute
      REPLICATION_UPDATE_INTERVAL: 60
      REPLICATION_RECHECK_INTERVAL: 30
      FREEZE: false
      IMPORT_WIKIPEDIA: false
      IMPORT_US_POSTCODES: false
      IMPORT_GB_POSTCODES: false
      IMPORT_TIGER_ADDRESSES: false
      THREADS: 8
      NOMINATIM_PASSWORD: {{PRODUCTION_NOMINATIM_PG_PASSWORD}}
      PGDATA: /var/lib/postgresql/14/main
      NOMINATIM_ADDRESS_LEVEL_CONFIG_URL: https://raw.githubusercontent.com/OpenHistoricalMap/nominatim-ui/master/address-levels.json
      UPDATE_MODE: continuous
      OSMSEED_WEB_API_DOMAIN: www.openhistoricalmap.org
    resources:
      enabled: false
      requests:
        memory: '1Gi'
        cpu: '2'
      limits:
        memory: '2Gi'
        cpu: '2'
    persistenceDisk:
      enabled: true
      accessMode: ReadWriteOnce
      mountPath: /var/lib/postgresql/14/main
      subPath: nominatim-pgdata
      # Minikube
      localVolumeHostPath: /mnt/nominatim-db-data
      localVolumeSize: 20Gi
      # AWS
      AWS_ElasticBlockStore_volumeID: {{PRODUCTION_NOMINATIM_DB_EBS}}
      AWS_ElasticBlockStore_size: 100Gi
      # GCP
      GCP_gcePersistentDisk_pdName: osmseed-disk-nominatim_db-v1
      GCP_gcePersistentDisk_size: 50Gi
    nodeSelector:
      enabled: true
      label_key: nodegroup_type
      label_value: web

# ====================================================================================================
# Variables for overpass-api
# ====================================================================================================
  overpassApi:
    enabled: true
    nodeSelector:
      enabled: true
      label_key: nodegroup_type
      label_value: web
    serviceAnnotations:
      service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: "300"
    env:
      OVERPASS_META: 'yes'
      OVERPASS_MODE: 'init'
      OVERPASS_PLANET_URL: 'http://planet.openhistoricalmap.org.s3.amazonaws.com/planet/planet-220815_0000.osm.pbf'
      OVERPASS_DIFF_URL: 'http://s3.amazonaws.com/planet.openhistoricalmap.org/replication/minute'
      OVERPASS_RULES_LOAD: '10'
      OVERPASS_PLANET_PREPROCESS: 'mv /db/planet.osm.bz2 /db/planet.osm.pbf && osmium cat -o /db/planet.osm.bz2 /db/planet.osm.pbf && rm /db/planet.osm.pbf'
      OVERPASS_REPLICATION_SEQUENCE_NUMBER: '810000'
    persistenceDisk:
      enabled: true
      accessMode: ReadWriteOnce
      AWS_ElasticBlockStore_volumeID: {{PRODUCTION_OVERPASS_API_DB_EBS}}
      AWS_ElasticBlockStore_size: 100Gi
    resources:
      enabled: false
      requests:
        memory: '1Gi'
        cpu: '2'
      limits:
        memory: '2Gi'
        cpu: '2'
# ====================================================================================================
# Variables for taginfo
# ====================================================================================================
  taginfo:
    enabled: true
    serviceAnnotations:
      service.beta.kubernetes.io/aws-load-balancer-connection-idle-timeout: "300"
    env:
      URL_PLANET_FILE_STATE: https://planet.openhistoricalmap.org.s3.amazonaws.com/planet/state.txt
      URL_HISTORY_PLANET_FILE_STATE: https://planet.openhistoricalmap.org.s3.amazonaws.com/planet/full-history/state.txt
      URL_PLANET_FILE: 'none'
      URL_HISTORY_PLANET_FILE: 'none'
      TIME_UPDATE_INTERVAL: 7d
      OVERWRITE_CONFIG_URL: https://raw.githubusercontent.com/OpenHistoricalMap/ohm-deploy/main/images/taginfo/taginfo-config-production.json
      TAGINFO_PROJECT_REPO: https://github.com/OpenHistoricalMap/taginfo-projects.git
      DOWNLOAD_DB: 'languages wiki'
      CREATE_DB: 'db projects chronology'
    resources:
      enabled: false
      requests:
        memory: '1Gi'
        cpu: '2'
      limits:
        memory: '2Gi'
        cpu: '2'
    nodeSelector:
      enabled: true
      label_key: nodegroup_type
      label_value: web
# ====================================================================================================
# Variables for osm-simple-metrics
# ====================================================================================================
  osmSimpleMetrics:
    enabled: true
    schedule: '0 2 * * *'
    resources:
      enabled: false
      requests:
        memory: '1Gi'
        cpu: '2'
      limits:
        memory: '2Gi'
        cpu: '2'
    nodeSelector:
      enabled: true
      label_key: nodegroup_type
      label_value: job
